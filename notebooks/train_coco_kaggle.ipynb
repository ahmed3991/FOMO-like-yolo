{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Train FOMO-like YOLOv8 on Kaggle (COCO 2017)\n",
                "\n",
                "This notebook allows you to train the model on Kaggle using the attached COCO 2017 dataset.\n",
                "\n",
                "## Instructions\n",
                "1. Add the **COCO 2017 Dataset** to your Kaggle notebook.\n",
                "   - Dataset URL: [https://www.kaggle.com/code/derekxue/coco-2017-dataset/data](https://www.kaggle.com/code/derekxue/coco-2017-dataset/data)\n",
                "   - Ensure it is mounted at `/kaggle/input/coco-2017-dataset/coco2017`.\n",
                "2. Upload the `tiny-vin` code to the notebook (or clone it).\n",
                "3. Run the cells below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 1. Setup Environment\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Assuming code is in the current directory or uploaded\n",
                "# If you uploaded the folder as a dataset, copy it to working dir to allow edits\n",
                "if not os.path.exists('requirements.txt'):\n",
                "    # Example: if code is in /kaggle/input/tiny-vin\n",
                "    # !cp -r /kaggle/input/tiny-vin/* .\n",
                "    pass\n",
                "\n",
                "# Install dependencies\n",
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 2. Prepare Labels\n",
                "# @markdown The COCO dataset on Kaggle is read-only. We need to convert the JSON annotations to YOLO format and save them in the working directory.\n",
                "\n",
                "import sys\n",
                "sys.path.append('.')\n",
                "from src.datasets.download.coco import convert_coco_json_to_yolo\n",
                "from pathlib import Path\n",
                "\n",
                "# Define paths\n",
                "KAGGLE_INPUT = Path('/kaggle/input/coco-2017-dataset/coco2017')\n",
                "WORKING_DIR = Path('/kaggle/working/data/coco')\n",
                "\n",
                "# Input Images (Read-only)\n",
                "train_img_dir = KAGGLE_INPUT / 'train2017'\n",
                "val_img_dir = KAGGLE_INPUT / 'val2017'\n",
                "\n",
                "# Output Labels (Writable)\n",
                "train_lbl_dir = WORKING_DIR / 'train/labels'\n",
                "val_lbl_dir = WORKING_DIR / 'val/labels'\n",
                "\n",
                "print(\"Converting Train Labels...\")\n",
                "convert_coco_json_to_yolo(\n",
                "    KAGGLE_INPUT / 'annotations/instances_train2017.json',\n",
                "    train_lbl_dir,\n",
                "    train_img_dir\n",
                ")\n",
                "\n",
                "print(\"\\nConverting Val Labels...\")\n",
                "convert_coco_json_to_yolo(\n",
                "    KAGGLE_INPUT / 'annotations/instances_val2017.json',\n",
                "    val_lbl_dir,\n",
                "    val_img_dir\n",
                ")\n",
                "\n",
                "print(\"\\nLabels prepared!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 3. Train Model\n",
                "# @markdown We point the training script to the read-only images and writable labels.\n",
                "\n",
                "!PYTHONPATH=. python scripts/train_coco.py \\\n",
                "    --train-image-dir /kaggle/input/coco-2017-dataset/coco2017/train2017 \\\n",
                "    --train-label-dir /kaggle/working/data/coco/train/labels \\\n",
                "    --val-image-dir /kaggle/input/coco-2017-dataset/coco2017/val2017 \\\n",
                "    --val-label-dir /kaggle/working/data/coco/val/labels \\\n",
                "    --batch-size 32 \\\n",
                "    --epochs 100 \\\n",
                "    --output-dir checkpoints_kaggle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 4. Visualize Predictions\n",
                "!PYTHONPATH=. python scripts/visualize_predictions.py \\\n",
                "    --checkpoint checkpoints_kaggle/best_model.pth \\\n",
                "    --image-dir /kaggle/input/coco-2017-dataset/coco2017/val2017 \\\n",
                "    --num-samples 5 \\\n",
                "    --output-dir predictions_kaggle"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}